{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying our RAG app with Anyscale + Ray\n",
    "\n",
    "In this notebook, we will deploy our RAG app using Ray Serve. Ray Serve is a scalable and programmable model serving library built on Ray. It is designed to simplify the process of serving and deploying models at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a Serve app locally\n",
    "\n",
    "The fastest way to develop a Ray Serve app is locally within the workspace. A Serve app running within a workspace behaves identically to a Serve app running as a production service, only it does not have a stable DNS name or fault tolerance.\n",
    "\n",
    "To get started, let's view file the called `main.py` which performs the following additions\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse\n",
    "from ray import serve\n",
    "\n",
    "... # same code as before\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@serve.deployment\n",
    "@serve.ingress(app)\n",
    "class QA:\n",
    "\n",
    "    # FastAPI will automatically parse the HTTP request for us.\n",
    "    @app.get(\"/answer\")\n",
    "    def answer(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int,\n",
    "        include_sources: bool = True,\n",
    "    ):\n",
    "        return StreamingResponse(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the app locally\n",
    "Run the command below to run the serve app locally on `localhost:8000`.\n",
    "\n",
    "If you want to deploy again, just run the command again to update the deployment.\n",
    "\n",
    "**Tip**: to more easily view Serve backend logs, you may find it convenient to use `serve run main:my_app --blocking` in a new VSCode terminal. This will block and print out application logs (exceptions, etc.) in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve run main:my_app --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a test request\n",
    "\n",
    "Run the following cell to query the local serve app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "params = dict(\n",
    "    query=\"How can I deploy Ray Serve to Kubernetes?\",\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/answer\", params=params)\n",
    "for chunk in response.iter_content(chunk_size=None, decode_unicode=True):\n",
    "    print(chunk.decode(), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to production as a service\n",
    "\n",
    "In order to enable fault tolerance and expose your app to the public internet, you must \"Deploy\" the application, which will create an Anyscale Service backed by a public load balancer. \n",
    "\n",
    "This service will run in a separate Ray cluster from the workspace, and will be monitored by the Anyscale control plane to recover on node failures. You will also be able to deploy rolling updates to the service without incurring downtime.\n",
    "\n",
    "Use the following command to deploy your app as `my_service`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve deploy main:my_app --name=my_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
