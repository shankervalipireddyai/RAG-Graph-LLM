import torch
import torch.nn as nn
from transformers import RobertaTokenizer, RobertaModel, AdamW
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import MultiLabelBinarizer

# Assuming 'filtered_df' contains the sentence and procedure columns
# Example columns: 'sentence_column' and 'procedure_labels_column'
sentences = filtered_df['extended_text'].tolist()  # Replace with your actual sentence column name
labels_procedures = filtered_df['procedure'].tolist()  # Replace with your actual procedure label column

# Convert lists of strings to list of lists (if it's a string representation of lists, use eval)
labels_procedures = [eval(label) if isinstance(label, str) else label for label in labels_procedures]

# MultiLabelBinarizer to one-hot encode the procedure labels
mlb = MultiLabelBinarizer()
encoded_labels = mlb.fit_transform(labels_procedures)

# Convert the encoded labels to a tensor
labels_procedures = torch.tensor(encoded_labels, dtype=torch.float32)

# Tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

def tokenize_sentences(sentences, tokenizer, max_len=512):
    inputs = [tokenizer(sentence, padding='max_length', truncation=True, max_length=max_len, return_tensors="pt") for sentence in sentences]
    input_ids = torch.cat([input['input_ids'] for input in inputs], dim=0)  # (batch_size, max_len)
    return input_ids

# Tokenize your input sentences
input_ids = tokenize_sentences(sentences, tokenizer)

# Dataset and DataLoader
train_dataset = TensorDataset(input_ids, labels_procedures)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Define the Model
class RobertaMultiLabelClassifier(nn.Module):
    def __init__(self, num_labels):
        super(RobertaMultiLabelClassifier, self).__init__()
        self.roberta = RobertaModel.from_pretrained('roberta-base')
        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_labels)
    
    def forward(self, input_ids):
        outputs = self.roberta(input_ids=input_ids)
        pooled_output = outputs.pooler_output  # Get the pooled output
        logits = self.classifier(pooled_output)
        return logits

# Initialize model
num_procedures = len(mlb.classes_)
model = RobertaMultiLabelClassifier(num_labels=num_procedures)

# Optimizer and Loss Function
optimizer = AdamW(model.parameters(), lr=1e-5)
loss_fn = nn.BCEWithLogitsLoss()

# Training Loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

epochs = 5
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        batch_input_ids, batch_labels = [x.to(device) for x in batch]

        # Forward pass
        logits = model(batch_input_ids)
        loss = loss_fn(logits, batch_labels)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

# Prediction Function
def predict(model, sentence):
    model.eval()
    tokens = tokenizer(sentence, return_tensors="pt", padding='max_length', truncation=True, max_length=512)
    input_ids = tokens['input_ids'].to(device)

    with torch.no_grad():
        logits = model(input_ids)

    # Apply sigmoid to get probabilities
    procedure_probs = torch.sigmoid(logits).squeeze().cpu().numpy()

    # Convert probabilities to binary predictions (threshold can be adjusted)
    procedure_preds = procedure_probs > 0.5

    # Map binary predictions to class names
    procedures = mlb.inverse_transform([procedure_preds])[0]

    return {
        "sentence": sentence,
        "procedures": list(procedures)
    }

# Example usage
example_sentence = "Implement network access control."
prediction = predict(model, example_sentence)
print(prediction)

# Predict on a dataframe
def predict_on_dataframe(model, dataframe):
    predictions = []
    for sentence in dataframe['extended_text']:
        result = predict(model, sentence)
        predictions.append(result)
    return predictions

# Get predictions for the first 200 rows
df_predictions = predict_on_dataframe(model, filtered_df.head(200))
print(df_predictions)









import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from transformers import AdamW, RobertaTokenizer
from torch.nn.utils.rnn import pad_sequence

# Assume you have a RoBERTa model and tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
model = model.to(device)  # Assuming 'model' is your pre-trained Roberta model

# Example sentence and labels (adjust as needed)
sentences = filtered_df['sentence_column'].tolist()  # Replace 'sentence_column' with your actual column name
labels_procedures = filtered_df['procedure_labels_column'].tolist()  # Replace with actual procedure label column

# Tokenization function with truncation and padding
def tokenize_sentences(sentences, tokenizer, max_len=512):
    inputs = [tokenizer(sentence, padding='max_length', truncation=True, max_length=max_len, return_tensors="pt") for sentence in sentences]
    input_ids = torch.cat([input['input_ids'] for input in inputs], dim=0)  # (batch_size, max_len)
    return input_ids

# Tokenize your input sentences
input_ids = tokenize_sentences(sentences, tokenizer)

# Convert labels to tensors
labels_procedures = torch.tensor(labels_procedures, dtype=torch.float32)

# Dataset and DataLoader
train_dataset = TensorDataset(input_ids, labels_procedures)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Optimizer and Loss Function
optimizer = AdamW(model.parameters(), lr=1e-5)
loss_fn = nn.BCEWithLogitsLoss()

# Training Loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

epochs = 5
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        batch_input_ids, batch_labels = [x.to(device) for x in batch]

        # Forward pass
        logits = model(batch_input_ids).logits  # .logits for transformer models
        loss = loss_fn(logits, batch_labels)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

 # Maximum length for RoBERTa model
MAX_LEN = 512

# Truncate input sequences to the maximum length and ensure padding if necessary
def preprocess_input(text):
    # Tokenize the input
    inputs = tokenizer(
        text,
        max_length=MAX_LEN,
        padding='max_length',  # Pad to the maximum length
        truncation=True,       # Truncate to the maximum length
        return_tensors='pt'    # Return PyTorch tensors
    )
    return inputs

# Example usage for a batch of input sentences
input_text = ["This is an example sentence.", "Another sentence for testing."]
batch_inputs = [preprocess_input(text) for text in input_text]




1. Install Required Libraries
First, ensure you have the required libraries installed:

bash
Copy code
pip install torch transformers scikit-learn pandas
2. Data Preprocessing
We'll use a filtered_df that contains sentences and corresponding multi-labels for procedures.

python
Copy code
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
from transformers import RobertaTokenizer

# Assume `filtered_df` is your dataset with the columns 'extended_text' (sentences) and 'procedure' (multi-labels)

# Example dataframe
# filtered_df = pd.read_csv('your_filtered_df.csv')

# Tokenization
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# Convert 'procedure' column into multi-hot vectors (multi-label binarization)
mlb_procedure = MultiLabelBinarizer()
filtered_df['procedure'] = filtered_df['procedure'].apply(lambda x: eval(x) if isinstance(x, str) else x)
multi_hot_procedures = mlb_procedure.fit_transform(filtered_df['procedure'])

# Tokenize sentences
def tokenize_sentence(sentence):
    return tokenizer(sentence, padding='max_length', truncation=True, return_tensors='pt')['input_ids'].squeeze()

# Apply tokenization to the entire dataset
filtered_df['input_ids'] = filtered_df['extended_text'].apply(tokenize_sentence)

# Splitting input_ids and labels for training
input_ids = torch.stack(filtered_df['input_ids'].values)
labels_procedures = torch.tensor(multi_hot_procedures, dtype=torch.float32)
3. Define the Model
Weâ€™ll build a RoBERTa model with a classification head for multi-label classification:

python
Copy code
import torch
import torch.nn as nn
from transformers import RobertaModel

class RobertaMultiLabelClassifier(nn.Module):
    def __init__(self, num_procedures):
        super(RobertaMultiLabelClassifier, self).__init__()
        self.roberta = RobertaModel.from_pretrained('roberta-base')
        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_procedures)
    
    def forward(self, input_ids):
        outputs = self.roberta(input_ids=input_ids)
        pooled_output = outputs.pooler_output
        logits = self.classifier(pooled_output)
        return logits

# Initialize the model
num_procedures = len(mlb_procedure.classes_)
model = RobertaMultiLabelClassifier(num_procedures)
4. Training Loop
We'll train the model using Binary Cross Entropy Loss and AdamW optimizer.

python
Copy code
from torch.utils.data import DataLoader, TensorDataset
from transformers import AdamW

# Dataset and DataLoader
train_dataset = TensorDataset(input_ids, labels_procedures)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Optimizer and Loss Function
optimizer = AdamW(model.parameters(), lr=1e-5)
loss_fn = nn.BCEWithLogitsLoss()

# Training Loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

epochs = 5
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        batch_input_ids, batch_labels = [x.to(device) for x in batch]

        # Forward pass
        logits = model(batch_input_ids)
        loss = loss_fn(logits, batch_labels)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")
5. Prediction Function
Now weâ€™ll write a function to make predictions for a given sentence:

python
Copy code
def predict(model, sentence):
    model.eval()
    tokens = tokenize_sentence(sentence).unsqueeze(0).to(device)  # Add batch dimension
    with torch.no_grad():
        logits = model(tokens)

    # Apply sigmoid to get probabilities
    procedure_probs = torch.sigmoid(logits).squeeze().cpu().numpy()

    # Convert probabilities to binary predictions (threshold can be adjusted)
    procedure_preds = procedure_probs > 0.5

    # Map binary predictions to procedure names
    procedures = mlb_procedure.inverse_transform([procedure_preds])[0]

    return {
        "sentence": sentence,
        "procedures": list(procedures)
    }
6. Evaluation and Model Validation
You can validate the model on a test dataset, but here we use an example prediction:

python
Copy code
# Example usage
sentence = "Implement network access control."
predictions = predict(model, sentence)
print(predictions)
7. Evaluate Model Performance
Weâ€™ll use accuracy, precision, recall, and F1-score to evaluate the model's performance.

python
Copy code
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate_model(model, test_loader):
    model.eval()
    all_labels = []
    all_preds = []
    with torch.no_grad():
        for batch in test_loader:
            batch_input_ids, batch_labels = [x.to(device) for x in batch]

            # Forward pass
            logits = model(batch_input_ids)
            procedure_probs = torch.sigmoid(logits)

            # Convert probabilities to binary predictions
            procedure_preds = procedure_probs > 0.5

            all_labels.append(batch_labels.cpu().numpy())
            all_preds.append(procedure_preds.cpu().numpy())

    # Calculate evaluation metrics
    all_labels = np.vstack(all_labels)
    all_preds = np.vstack(all_preds)
    
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='micro')
    recall = recall_score(all_labels, all_preds, average='micro')
    f1 = f1_score(all_labels, all_preds, average='micro')

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")

# Example test evaluation
test_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)  # You should use a real test dataset
evaluate_model(model, test_loader)






















1. Data Preprocessing
python
Copy code
import pandas as pd
import torch
from sklearn.preprocessing import MultiLabelBinarizer
from transformers import RobertaTokenizer
from torch.utils.data import Dataset, DataLoader

# Load the data (filtered_df should contain 'sentence' and 'procedures' columns)
filtered_df = pd.read_csv('filtered_df.csv')

# Preprocess procedures (multi-label binarization)
mlb_procedure = MultiLabelBinarizer()
filtered_df['procedures'] = filtered_df['procedures'].apply(eval)  # Convert string to list
y_procedures = mlb_procedure.fit_transform(filtered_df['procedures'])

# Initialize tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

class SentenceProcedureDataset(Dataset):
    def __init__(self, sentences, labels, tokenizer, max_length=128):
        self.sentences = sentences
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, idx):
        sentence = self.sentences[idx]
        label = self.labels[idx]
        encoding = self.tokenizer.encode_plus(
            sentence,
            add_special_tokens=True,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(label, dtype=torch.float)
        }

# Create dataset and data loaders
dataset = SentenceProcedureDataset(filtered_df['sentence'].values, y_procedures, tokenizer)
train_loader = DataLoader(dataset, batch_size=16, shuffle=True)

2. Model Definition
python
Copy code
import torch.nn as nn
from transformers import RobertaModel

class RobertaForMultiLabelClassification(nn.Module):
    def __init__(self, num_procedures):
        super(RobertaForMultiLabelClassification, self).__init__()
        self.roberta = RobertaModel.from_pretrained('roberta-base')
        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_procedures)
        self.sigmoid = nn.Sigmoid()

    def forward(self, input_ids, attention_mask):
        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)
        cls_output = outputs[1]  # [CLS] token output
        logits = self.classifier(cls_output)
        return logits

# Initialize model
model = RobertaForMultiLabelClassification(num_procedures=y_procedures.shape[1])
3. Training Loop
python
Copy code
import torch.optim as optim

# Initialize optimizer and loss function
optimizer = optim.AdamW(model.parameters(), lr=2e-5)
loss_fn = nn.BCEWithLogitsLoss()

# Training function
def train(model, dataloader, optimizer, loss_fn, epochs=3):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for batch in dataloader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            labels = batch['labels']

            # Forward pass
            outputs = model(input_ids, attention_mask)
            loss = loss_fn(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')

# Train the model
train(model, train_loader, optimizer, loss_fn, epochs=3)
4. Prediction Function
python
Copy code
def tokenize_sentence(sentence):
    encoding = tokenizer.encode_plus(
        sentence,
        add_special_tokens=True,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt'
    )
    return encoding['input_ids'], encoding['attention_mask']

def predict(model, sentence):
    model.eval()
    input_ids, attention_mask = tokenize_sentence(sentence)
    input_ids = input_ids.squeeze(0)  # Remove batch dimension
    attention_mask = attention_mask.squeeze(0)

    with torch.no_grad():
        logits = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))
        probs = torch.sigmoid(logits).squeeze().cpu().numpy()

    # Convert probabilities to binary predictions (threshold can be adjusted)
    preds = probs > 0.5

    # Map predictions to procedure names
    predicted_procedures = mlb_procedure.inverse_transform([preds])[0]

    return list(predicted_procedures)

# Example usage
sentence = "Implement network access control."
predictions = predict(model, sentence)
print(predictions)
5. Evaluation
python
Copy code
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate(model, dataloader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            labels = batch['labels']

            logits = model(input_ids, attention_mask)
            probs = torch.sigmoid(logits).cpu().numpy()
            preds = (probs > 0.5).astype(int)

            all_preds.append(preds)
            all_labels.append(labels.cpu().numpy())

    # Convert lists to arrays
    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)

    # Calculate metrics
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='micro')
    recall = recall_score(all_labels, all_preds, average='micro')
    f1 = f1_score(all_labels, all_preds, average='micro')

    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')

# Evaluate the model
evaluate(model, train_loader)
Summary of Steps:
Data Preprocessing:

Sentences are tokenized using the RoBERTa tokenizer.
Procedures are binarized using MultiLabelBinarizer.
Model Building:

A RoBERTa model is used to predict multiple procedures for each sentence using a multi-label classification head.
Training:

The model is trained using BCEWithLogitsLoss and optimized using AdamW optimizer.
Prediction:

Given a new sentence, the model predicts which procedures it maps to.
Evaluation:

Metrics such as accuracy, precision, recall, and F1-score are calculated to evaluate the model's performance.



















import plotly.express as px
import pandas as pd

# Explode the 'procedure' column to separate each procedure into its own row
procedures_df = filtered_df.explode('procedure')

# Group by 'procedure' and count how many sentences (rows) are associated with each procedure
procedure_sentence_count = procedures_df.groupby('procedure').size().reset_index(name='sentence_count')

# Sort by sentence count for better visualization
procedure_sentence_count = procedure_sentence_count.sort_values(by='sentence_count', ascending=False)

# Create a bar chart with Plotly
fig = px.bar(procedure_sentence_count,
             x='procedure', 
             y='sentence_count', 
             hover_name='procedure',  # This will show procedure name on hover
             title='Sentence Count per Procedure')

# Customize layout
fig.update_layout(
    xaxis_title='Procedure',
    yaxis_title='Sentence Count',
    xaxis_tickangle=-45,  # Rotate x-axis labels
    height=600,
    width=1000
)

# Show the plot
fig.show()


import matplotlib.pyplot as plt
import pandas as pd

# Assuming 'procedure' column contains a list of procedures for each row in filtered_df
# First, explode the 'procedure' column to separate each procedure into its own row
procedures_df = filtered_df.explode('procedure')

# Group by the procedure and count occurrences
procedure_counts = procedures_df['procedure'].value_counts()

# Plot the chart
plt.figure(figsize=(10, 8))  # Set the figure size
procedure_counts.plot(kind='bar', color='skyblue')

# Set title and labels
plt.title('Procedure Distribution', fontsize=14)
plt.xlabel('Procedure', fontsize=12)
plt.ylabel('Count', fontsize=12)

# Rotate x labels for better readability
plt.xticks(rotation=90)

# Show the plot
plt.tight_layout()
plt.show()


# Assuming your dataframe is named 'filtered_df' and has a 'Procedure Description' column

# Apply the predict function to all sentences in the 'Procedure Description' column
def apply_prediction(row):
    sentence = row['Procedure Description']  # Modify if needed
    return predict(model, sentence)

# Run prediction for each row in the dataframe and store the results in new columns
filtered_df[['predicted_procedures', 'predicted_objectives', 'predicted_standards', 'predicted_domains']] = (
    filtered_df.apply(lambda row: pd.Series(apply_prediction(row)), axis=1)
)

# Display the dataframe with the predictions
print(filtered_df[['Procedure Description', 'predicted_procedures', 'predicted_objectives', 'predicted_standards', 'predicted_domains']].head())


import boto3

# Variables for the role and S3 bucket
role_arn = "arn:aws:iam::123456789012:role/YourRoleName"  # Replace with your Role ARN
bucket_name = "your-bucket-name"

# Create an STS client
sts_client = boto3.client('sts')

# Assume the role
assumed_role = sts_client.assume_role(
    RoleArn=role_arn,
    RoleSessionName="S3AccessSession"
)

# Extract the temporary credentials from the response
credentials = assumed_role['Credentials']
access_key = credentials['AccessKeyId']
secret_key = credentials['SecretAccessKey']
session_token = credentials['SessionToken']

# Create a new S3 client using the temporary credentials
s3_client = boto3.client(
    's3',
    aws_access_key_id=access_key,
    aws_secret_access_key=secret_key,
    aws_session_token=session_token
)

# List the contents of the S3 bucket
response = s3_client.list_objects_v2(Bucket=bucket_name)

# Print the contents of the bucket
if 'Contents' in response:
    for obj in response['Contents']:
        print(obj['Key'])
else:
    print("Bucket is empty or you don't have permission to list its contents.")

To train the HierarchicalRoberta model using the provided code and data, hereâ€™s a step-by-step guide to the training algorithm:

Step 1: Load Necessary Libraries

import pandas as pd
import torch
from torch.utils.data import DataLoader, Dataset
from transformers import RobertaTokenizer, RobertaConfig
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

Step 2: Load Data

	â€¢	Load the Control Structure:

control_data = pd.read_pickle('control.pkl')


	â€¢	Load Annotated Sentences:

annotated_data = pd.read_pickle('annotated_data.pkl')



Step 3: Verify and Encode Labels

	â€¢	Extract and Encode the Labels:

# Fill NaN or empty strings with a placeholder like 'Unknown'
control_data['domain'].fillna('Unknown', inplace=True)
control_data['domain'].replace('', 'Unknown', inplace=True)

annotated_data['domain'].fillna('Unknown', inplace=True)
annotated_data['domain'].replace('', 'Unknown', inplace=True)


# Extract unique values for encoding
valid_domains = control_data['domain'].unique()
valid_standards = control_data['standard'].unique()
valid_objectives = control_data['objective'].unique()
valid_procedures = control_data['procedure'].unique()

# Initialize Label Encoders
domain_encoder = LabelEncoder().fit(valid_domains)
standard_encoder = LabelEncoder().fit(valid_standards)
objective_encoder = LabelEncoder().fit(valid_objectives)
procedure_encoder = LabelEncoder().fit(valid_procedures)

# Encode the annotated data
annotated_data['domain'] = domain_encoder.transform(annotated_data['domain'])
annotated_data['standard'] = standard_encoder.transform(annotated_data['standard'])
annotated_data['objective'] = objective_encoder.transform(annotated_data['objective'])
annotated_data['procedure'] = procedure_encoder.transform(annotated_data['procedure'])



Step 4: Prepare the Dataset

	â€¢	Create a Custom Dataset Class:

class CustomDataset(Dataset):
    def __init__(self, sentences, labels, tokenizer, max_len):
        self.sentences = sentences
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, index):
        sentence = self.sentences[index]
        label = self.labels[index]

        encoding = self.tokenizer.encode_plus(
            sentence,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            return_attention_mask=True,
            return_tensors='pt',
            truncation=True
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }


	â€¢	Initialize the Tokenizer:

tokenizer = RobertaTokenizer.from_pretrained('roberta-base')


	â€¢	Prepare Data for Training and Validation:

# Combine labels into a single array
labels = annotated_data[['domain', 'standard', 'objective', 'procedure']].values

# Split into training and validation sets
train_sentences, val_sentences, train_labels, val_labels = train_test_split(
    annotated_data['sentence'].values,
    labels,
    test_size=0.2,
    random_state=42
)

# Create Dataset objects
train_dataset = CustomDataset(
    sentences=train_sentences,
    labels=train_labels,
    tokenizer=tokenizer,
    max_len=128
)

val_dataset = CustomDataset(
    sentences=val_sentences,
    labels=val_labels,
    tokenizer=tokenizer,
    max_len=128
)

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)



Step 5: Initialize the Model

	â€¢	Load Model Configuration:

config = RobertaConfig.from_pretrained('roberta-base')


	â€¢	Initialize the Hierarchical Model:

model = HierarchicalRoberta(config)



Step 6: Set Up the Training Loop

	â€¢	Define Optimizer and Loss:

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)


	â€¢	Training Loop:

def train_epoch(model, data_loader, optimizer, device):
    model = model.train()
    total_loss = 0

    for batch in data_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()

        loss, _, _, _, _ = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(data_loader)

def eval_model(model, data_loader, device):
    model = model.eval()
    total_loss = 0

    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            loss, _, _, _, _ = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )

            total_loss += loss.item()

    return total_loss / len(data_loader)



Step 7: Train the Model

	â€¢	Train the Model Over Several Epochs:

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

epochs = 3
for epoch in range(epochs):
    print(f'Epoch {epoch + 1}/{epochs}')
    train_loss = train_epoch(model, train_loader, optimizer, device)
    val_loss = eval_model(model, val_loader, device)

    print(f'Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')



Step 8: Save the Trained Model

	â€¢	Save the Model and Tokenizer:

model.save_pretrained('./hierarchical_roberta')
tokenizer.save_pretrained('./hierarchical_roberta')



from transformers import RobertaModel, RobertaConfig, RobertaPreTrainedModel
import torch.nn as nn
import torch

class HierarchicalRoberta(RobertaPreTrainedModel):
    def __init__(self, config):
        super(HierarchicalRoberta, self).__init__(config)
        self.roberta = RobertaModel(config)

        # Define classifiers for each hierarchical level
        self.domain_classifier = nn.Linear(config.hidden_size, len(domain_encoder.classes_))
        self.standard_classifier = nn.Linear(config.hidden_size, len(standard_encoder.classes_))
        self.objective_classifier = nn.Linear(config.hidden_size, len(objective_encoder.classes_))
        self.procedure_classifier = nn.Linear(config.hidden_size, len(procedure_encoder.classes_))

        self.init_weights()

    def forward(self, input_ids, attention_mask, labels=None):
        # Get the RoBERTa output
        outputs = self.roberta(input_ids, attention_mask=attention_mask)
        sequence_output = outputs[0][:, 0, :]  # Use the [CLS] token's output

        # Predict each level sequentially
        domain_logits = self.domain_classifier(sequence_output)
        standard_logits = self.standard_classifier(sequence_output)
        objective_logits = self.objective_classifier(sequence_output)
        procedure_logits = self.procedure_classifier(sequence_output)

        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            domain_loss = loss_fct(domain_logits, labels[:, 0])
            standard_loss = loss_fct(standard_logits, labels[:, 1])
            objective_loss = loss_fct(objective_logits, labels[:, 2])
            procedure_loss = loss_fct(procedure_logits, labels[:, 3])

            total_loss = domain_loss + standard_loss + objective_loss + procedure_loss
            return total_loss, domain_logits, standard_logits, objective_logits, procedure_logits

        return domain_logits, standard_logits, objective_logits, procedure_logits




def predict(model, tokenizer, sentence):
    model.eval()
    
    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    with torch.no_grad():
        domain_logits, standard_logits, objective_logits, procedure_logits = model(input_ids, attention_mask)

    # Convert logits to predicted labels
    domain_pred = torch.argmax(domain_logits, dim=1).item()
    standard_pred = torch.argmax(standard_logits, dim=1).item()
    objective_pred = torch.argmax(objective_logits, dim=1).item()
    procedure_pred = torch.argmax(procedure_logits, dim=1).item()

    # Decode labels
    domain_label = domain_encoder.inverse_transform([domain_pred])[0]
    standard_label = standard_encoder.inverse_transform([standard_pred])[0]
    objective_label = objective_encoder.inverse_transform([objective_pred])[0]
    procedure_label = procedure_encoder.inverse_transform([procedure_pred])[0]

    return {
        'domain': domain_label,
        'standard': standard_label,
        'objective': objective_label,
        'procedure': procedure_label
    }

# Example usage
sentence = "Ensure that all data at rest is encrypted using AES-256."
prediction = predict(model, tokenizer, sentence)
print(prediction)


Sentence: "Encrypt all backup files using AES-256 before transferring to cloud storage."

Expected Domain: Encryption
Expected Standard: Data at Rest Encryption
Expected Objective: Secure Backup Encryption
Expected Procedure: AES-256 Encryption Procedure
Explanation: The sentence explicitly mentions "AES-256," which is a strong indicator that the correct procedure should involve the AES-256 encryption method. The context of encrypting backups for secure transfer is aligned with common encryption procedures, making it likely the model will predict this correctly.

Sentence: "Ensure multi-factor authentication is enforced for all user logins."

Expected Domain: Authentication
Expected Standard: User Access Control
Expected Objective: Multi-Factor Authentication
Expected Procedure: Token-Based MFA Implementation
Explanation: The sentence mentions "multi-factor authentication," a specific technique used to enhance security. The model, having been trained on similar sentences, should predict the procedure related to implementing MFA, such as "Token-Based MFA Implementation."

Sentence: "All passwords should be hashed using the SHA-256 algorithm before storage."

Expected Domain: Encryption
Expected Standard: Password Protection
Expected Objective: Password Hashing
Expected Procedure: SHA-256 Hashing Procedure
Explanation: "SHA-256 algorithm" directly references a specific procedure for hashing passwords, making it highly likely that the model will predict the correct procedure, "SHA-256 Hashing Procedure."

Sentence: "Implement firewall rules to block unauthorized access to the database."

Expected Domain: Network Security
Expected Standard: Access Control
Expected Objective: Database Security
Expected Procedure: Firewall Configuration Procedure
Explanation: The mention of "firewall rules" suggests a specific network security procedure. The model should predict a procedure related to configuring firewall rules, such as "Firewall Configuration Procedure."

Sentence: "Perform regular audits to ensure compliance with data protection regulations."

Expected Domain: Compliance
Expected Standard: Data Protection Compliance
Expected Objective: Regular Audits
Expected Procedure: Audit Procedure Implementation
Explanation: The sentence refers to "regular audits," which are a procedural aspect of compliance. The model should identify the related procedure as "Audit Procedure Implementation."

Why These Predictions are Likely Correct
Clear Keywords: Each sentence contains specific keywords or phrases that are closely tied to a known procedure, such as "AES-256," "multi-factor authentication," or "firewall rules." These keywords are likely to have been encountered during training, making the model's prediction more accurate.

Contextual Information: The context provided by the sentence helps the model infer the correct procedure. For instance, the context of "user logins" in conjunction with "multi-factor authentication" strongly suggests an MFA-related procedure.

Hierarchical Dependencies: The model predicts procedures after first predicting domains, standards, and objectives. This sequential prediction allows it to refine its final prediction based on the hierarchical context provided by the earlier predictions.

Summary of the Steps:

	1.	Load Data: Load the control structure from control.pkl and the annotated sentences from annotated_data.pkl.
	2.	Verify & Encode Labels: Use LabelEncoder to encode labels for domain, standard, objective, and procedure based on the control structure.
	3.	Prepare Dataset: Create a custom PyTorch Dataset to handle tokenization and data formatting.
	4.	Initialize Model: Set up the RoBERTa model for hierarchical classification.
	5.	Train Model: Run the training loop with a defined optimizer and loss function.
	6.	Save Model: After training, save the model and tokenizer for later use.

This step-by-step process allows you to train a hierarchical classification model using RoBERTa, tailored for the task of mapping sentences to their respective control structures.





o evaluate the performance of your hierarchical classification model using metrics like accuracy, precision, recall, F1-score, and a confusion matrix, you can use the following code. This code assumes that you have split your data into training and validation sets and have a trained model ready for evaluation.

1. Import Required Libraries
python
Copy code
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import torch

# Assuming you have the following objects:
# model: the trained model
# tokenizer: the tokenizer used for preprocessing
# val_dataset: the validation dataset
# domain_encoder, standard_encoder, objective_encoder, procedure_encoder: label encoders for each hierarchical level

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
2. Define Evaluation Function
python
Copy code
def evaluate(model, val_dataset):
    model.eval()
    
    true_labels = []
    pred_labels = []

    for batch in val_dataset:
        inputs = tokenizer(batch['sentence'], return_tensors='pt', truncation=True, padding=True).to(device)
        labels = batch['labels'].to(device)

        with torch.no_grad():
            domain_logits, standard_logits, objective_logits, procedure_logits = model(
                input_ids=inputs['input_ids'],
                attention_mask=inputs['attention_mask']
            )

        # Convert logits to predictions
        domain_preds = torch.argmax(domain_logits, dim=1).cpu().numpy()
        standard_preds = torch.argmax(standard_logits, dim=1).cpu().numpy()
        objective_preds = torch.argmax(objective_logits, dim=1).cpu().numpy()
        procedure_preds = torch.argmax(procedure_logits, dim=1).cpu().numpy()

        # Combine predictions and true labels
        pred_labels.append(np.stack([domain_preds, standard_preds, objective_preds, procedure_preds], axis=1))
        true_labels.append(labels.cpu().numpy())

    pred_labels = np.concatenate(pred_labels)
    true_labels = np.concatenate(true_labels)

    return true_labels, pred_labels
3. Calculate Metrics
python
Copy code
def calculate_metrics(true_labels, pred_labels, encoder, level_name):
    accuracy = accuracy_score(true_labels, pred_labels)
    precision = precision_score(true_labels, pred_labels, average='weighted')
    recall = recall_score(true_labels, pred_labels, average='weighted')
    f1 = f1_score(true_labels, pred_labels, average='weighted')
    conf_matrix = confusion_matrix(true_labels, pred_labels)

    print(f"{level_name} Level Metrics:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"Confusion Matrix:\n{conf_matrix}\n")
4. Run Evaluation on All Levels
python
Copy code
# Evaluate the model on the validation set
true_labels, pred_labels = evaluate(model, val_dataset)

# For each level, calculate and print the metrics
calculate_metrics(true_labels[:, 0], pred_labels[:, 0], domain_encoder, "Domain")
calculate_metrics(true_labels[:, 1], pred_labels[:, 1], standard_encoder, "Standard")
calculate_metrics(true_labels[:, 2], pred_labels[:, 2], objective_encoder, "Objective")
calculate_metrics(true_labels[:, 3], pred_labels[:, 3], procedure_encoder, "Procedure")
5. Example Usage
After running the code, you will get accuracy, precision, recall, F1-score, and a confusion matrix for each hierarchical level (Domain, Standard, Objective, and Procedure). Here's an example of what the output might look like:

plaintext
Copy code
Domain Level Metrics:
Accuracy: 0.8250
Precision: 0.8205
Recall: 0.8250
F1-Score: 0.8227
Confusion Matrix:
[[50  2  1]
 [ 5 38  7]
 [ 0  3 64]]

Standard Level Metrics:
Accuracy: 0.7800
Precision: 0.7734
Recall: 0.7800
F1-Score: 0.7767
Confusion Matrix:
[[45  8  2]
 [ 6 35  9]
 [ 1  5 58]]

...

Procedure Level Metrics:
Accuracy: 0.7650
Precision: 0.7590
Recall: 0.7650
F1-Score: 0.7619
Confusion Matrix:
[[42  7  3]
 [ 8 32 10]
 [ 3  4 61]]
Explanation:
Accuracy: The proportion of true results (both true positives and true negatives) among the total number of cases examined.
Precision: The proportion of true positive predictions among all positive predictions (how many selected items are relevant).
Recall: The proportion of true positive predictions among all actual positives (how many relevant items are selected).
F1-Score: The harmonic mean of precision and recall, providing a balance between the two.
Confusion Matrix: A table used to describe the performance of a classification model, showing the correct and incorrect predictions.
By analyzing these metrics, you can assess the model's performance and identify areas where it might need improvement.




# Count unique mappings for procedures, objectives, standards, and domains
grouped_df = merged_df.groupby('sentence').agg({
    'procedure': pd.Series.nunique,  # Count unique procedures
    'objective': pd.Series.nunique,  # Count unique objectives
    'standard': pd.Series.nunique,   # Count unique standards
    'domain': pd.Series.nunique      # Count unique domains
}).reset_index()

# Rename columns for clarity
grouped_df.rename(columns={
    'procedure': 'procedure_count',
    'objective': 'objective_count',
    'standard': 'standard_count',
    'domain': 'domain_count'
}, inplace=True)


# Extract distinct procedures
distinct_procedures = filtered_df['procedures'].explode().drop_duplicates().reset_index(drop=True)

# Extract distinct objectives
distinct_objectives = filtered_df['objectives'].explode().drop_duplicates().reset_index(drop=True)

# Extract distinct standards
distinct_standards = filtered_df['standards'].explode().drop_duplicates().reset_index(drop=True)

# Extract distinct domains
distinct_domains = filtered_df['domains'].explode().drop_duplicates().reset_index(drop=True)

# Display the distinct values
print("Distinct Procedures:\n", distinct_procedures)
print("\nDistinct Objectives:\n", distinct_objectives)
print("\nDistinct Standards:\n", distinct_standards)
print("\nDistinct Domains:\n", distinct_domains)






To create a hierarchical multi-class model using RoBERTa that can handle sentences mapped to multiple procedures, objectives, standards, and domains, weâ€™ll first prepare the data and then define and fine-tune a model. This process involves the following steps:

1. Data Preparation

Data Overview:

	â€¢	Control Data: Contains domains, standards, objectives, and procedures.
	â€¢	Sentence Data: Contains sentences that need to be mapped to the control structure.

Data Cleaning and Merging:

The key is to merge these datasets correctly, ensure there are no NaN values, and then structure the data so that itâ€™s ready for model training.

import pandas as pd
import numpy as np

# Assume control_df and sentences_df are your dataframes loaded from ctrl.pkl and sentences.pkl respectively

# Merge the dataframes on a common key if available
merged_df = pd.merge(sentences_df, control_df, how='inner', on='common_key')  # replace 'common_key' with your actual key

# Drop NaNs across necessary columns
filtered_df = merged_df.dropna(subset=['domain', 'standard', 'objective', 'procedure'])

# Handle cases where sentences map to multiple procedures, objectives, etc.
filtered_df['procedures'] = filtered_df['procedures'].apply(lambda x: x.split(',') if isinstance(x, str) else x)
filtered_df['objectives'] = filtered_df['objectives'].apply(lambda x: x.split(',') if isinstance(x, str) else x)
filtered_df['standards'] = filtered_df['standards'].apply(lambda x: x.split(',') if isinstance(x, str) else x)
filtered_df['domains'] = filtered_df['domains'].apply(lambda x: x.split(',') if isinstance(x, str) else x)

# Remove NaN entries from lists
filtered_df = filtered_df.applymap(lambda x: [i for i in x if i] if isinstance(x, list) else x)

# Filter out empty lists to make sure there's no missing data
filtered_df = filtered_df[filtered_df['procedures'].str.len() > 0]

2. Model Definition

Hierarchical Multi-Label Classification with RoBERTa

Weâ€™ll define a custom model using the transformers library by extending RobertaPreTrainedModel. The model will predict at each level of the hierarchy (procedure, objective, standard, domain).

import torch
import torch.nn as nn
from transformers import RobertaModel, RobertaPreTrainedModel, RobertaTokenizer

class HierarchicalRobertaMultiLabel(RobertaPreTrainedModel):
    def __init__(self, config):
        super(HierarchicalRobertaMultiLabel, self).__init__(config)
        self.roberta = RobertaModel(config)
        
        # Linear layers for each hierarchical level
        self.procedure_classifier = nn.Linear(config.hidden_size, len(procedure_encoder.classes_))
        self.objective_classifier = nn.Linear(config.hidden_size, len(objective_encoder.classes_))
        self.standard_classifier = nn.Linear(config.hidden_size, len(standard_encoder.classes_))
        self.domain_classifier = nn.Linear(config.hidden_size, len(domain_encoder.classes_))

        self.init_weights()

    def forward(self, input_ids, attention_mask=None, labels=None):
        outputs = self.roberta(input_ids, attention_mask=attention_mask)
        sequence_output = outputs[0][:, 0, :]  # Using CLS token's representation

        procedure_logits = self.procedure_classifier(sequence_output)
        objective_logits = self.objective_classifier(sequence_output)
        standard_logits = self.standard_classifier(sequence_output)
        domain_logits = self.domain_classifier(sequence_output)

        return procedure_logits, objective_logits, standard_logits, domain_logits

3. Fine-Tuning

Data Encoding

Use MultiLabelBinarizer for the multi-label data:

from sklearn.preprocessing import MultiLabelBinarizer

procedure_encoder = MultiLabelBinarizer().fit(filtered_df['procedures'])
objective_encoder = MultiLabelBinarizer().fit(filtered_df['objectives'])
standard_encoder = MultiLabelBinarizer().fit(filtered_df['standards'])
domain_encoder = MultiLabelBinarizer().fit(filtered_df['domains'])

# Encode the labels
y_procedures = procedure_encoder.transform(filtered_df['procedures'])
y_objectives = objective_encoder.transform(filtered_df['objectives'])
y_standards = standard_encoder.transform(filtered_df['standards'])
y_domains = domain_encoder.transform(filtered_df['domains'])

Training Loop

from transformers import RobertaTokenizer, AdamW
from torch.utils.data import DataLoader, TensorDataset
import torch

# Load tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# Tokenize the sentences
encodings = tokenizer(list(filtered_df['sentence']), truncation=True, padding=True, max_length=128)

input_ids = torch.tensor(encodings['input_ids'])
attention_mask = torch.tensor(encodings['attention_mask'])
labels_procedures = torch.tensor(y_procedures, dtype=torch.float32)
labels_objectives = torch.tensor(y_objectives, dtype=torch.float32)
labels_standards = torch.tensor(y_standards, dtype=torch.float32)
labels_domains = torch.tensor(y_domains, dtype=torch.float32)

# Create a dataset and dataloader
dataset = TensorDataset(input_ids, attention_mask, labels_procedures, labels_objectives, labels_standards, labels_domains)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# Model and optimizer
model = HierarchicalRobertaMultiLabel.from_pretrained('roberta-base')
optimizer = AdamW(model.parameters(), lr=2e-5)

# Training loop
for epoch in range(3):
    model.train()
    total_loss = 0

    for batch in dataloader:
        b_input_ids, b_attention_mask, b_labels_procedures, b_labels_objectives, b_labels_standards, b_labels_domains = batch

        model.zero_grad()

        #



        # Forward pass
        procedure_logits, objective_logits, standard_logits, domain_logits = model(
            input_ids=b_input_ids,
            attention_mask=b_attention_mask
        )

        # Loss calculation for multi-label classification
        loss_fn = nn.BCEWithLogitsLoss()

        procedure_loss = loss_fn(procedure_logits, b_labels_procedures)
        objective_loss = loss_fn(objective_logits, b_labels_objectives)
        standard_loss = loss_fn(standard_logits, b_labels_standards)
        domain_loss = loss_fn(domain_logits, b_labels_domains)

        # Total loss
        loss = procedure_loss + objective_loss + standard_loss + domain_loss
        total_loss += loss.item()

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

    avg_train_loss = total_loss / len(dataloader)
    print(f"Epoch {epoch + 1}, Loss: {avg_train_loss}")







def predict(model, sentence):
    model.eval()
    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=128)
    input_ids = inputs['input_ids']
    attention_mask = inputs['attention_mask']

    with torch.no_grad():
        procedure_logits, objective_logits, standard_logits, domain_logits = model(input_ids, attention_mask)

    # Convert logits to probabilities
    procedure_probs = torch.sigmoid(procedure_logits).squeeze().tolist()
    objective_probs = torch.sigmoid(objective_logits).squeeze().tolist()
    standard_probs = torch.sigmoid(standard_logits).squeeze().tolist()
    domain_probs = torch.sigmoid(domain_logits).squeeze().tolist()

    # Get the most probable labels (threshold can be adjusted)
    procedure_preds = [procedure_encoder.classes_[i] for i, p in enumerate(procedure_probs) if p > 0.5]
    objective_preds = [objective_encoder.classes_[i] for i, p in enumerate(objective_probs) if p > 0.5]
    standard_preds = [standard_encoder.classes_[i] for i, p in enumerate(standard_probs) if p > 0.5]
    domain_preds = [domain_encoder.classes_[i] for i, p in enumerate(domain_probs) if p > 0.5]

    return {
        "procedures": procedure_preds,
        "objectives": objective_preds,
        "standards": standard_preds,
        "domains": domain_preds
    }

# Example usage
sentence = "Implementing AES-256 encryption for securing data at rest."
predictions = predict(model, sentence)
print(predictions)







from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix

def evaluate_model(model, dataloader):
    model.eval()
    all_preds_procedures = []
    all_preds_objectives = []
    all_preds_standards = []
    all_preds_domains = []
    
    all_labels_procedures = []
    all_labels_objectives = []
    all_labels_standards = []
    all_labels_domains = []
    
    with torch.no_grad():
        for batch in dataloader:
            b_input_ids, b_attention_mask, b_labels_procedures, b_labels_objectives, b_labels_standards, b_labels_domains = batch

            procedure_logits, objective_logits, standard_logits, domain_logits = model(
                input_ids=b_input_ids,
                attention_mask=b_attention_mask
            )

            # Get predicted labels
            procedure_preds = (torch.sigmoid(procedure_logits) > 0.5).float()
            objective_preds = (torch.sigmoid(objective_logits) > 0.5).float()
            standard_preds = (torch.sigmoid(standard_logits) > 0.5).float()
            domain_preds = (torch.sigmoid(domain_logits) > 0.5).float()

            all_preds_procedures.append(procedure_preds.cpu().numpy())
            all_preds_objectives.append(objective_preds.cpu().numpy())
            all_preds_standards.append(standard_preds.cpu().numpy())
            all_preds_domains.append(domain_preds.cpu().numpy())
            
            all_labels_procedures.append(b_labels_procedures.cpu().numpy())
            all_labels_objectives.append(b_labels_objectives.cpu().numpy())
            all_labels_standards.append(b_labels_standards.cpu().numpy())
            all_labels_domains.append(b_labels_domains.cpu().numpy())

    # Flatten the arrays
    y_true_procedures = np.concatenate(all_labels_procedures, axis=0)
    y_pred_procedures = np.concatenate(all_preds_procedures, axis=0)

    y_true_objectives = np.concatenate(all_labels_objectives, axis=0)
    y_pred_objectives = np.concatenate(all_preds_objectives, axis=0)

    y_true_standards = np.concatenate(all_labels_standards, axis=0)
    y_pred_standards = np.concatenate(all_preds_standards, axis=0)

    y_true_domains = np.concatenate(all_labels_domains, axis=0)
    y_pred_domains = np.concatenate(all_preds_domains, axis=0)

    # Metrics calculation
    metrics = {}
    for label, y_true, y_pred in [("procedures", y_true_procedures, y_pred_procedures),
                                  ("objectives", y_true_objectives, y_pred_objectives),
                                  ("standards", y_true_standards, y_pred_standards),
                                  ("domains", y_true_domains, y_pred_domains)]:
        
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='weighted')
        recall = recall_score(y_true, y_pred, average='weighted')
        f1 = f1_score(y_true, y_pred, average='weighted')
        conf_matrix = multilabel_confusion_matrix(y_true, y_pred)

        metrics[label] = {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "confusion_matrix": conf_matrix
        }

    return metrics

# Evaluate the model on the validation set
metrics = evaluate_model(model, dataloader)
print(metrics)



Here are some example sentences that might be used with the predict function to generate hierarchical predictions:

1. Data Encryption

sentence = "Implementing AES-256 encryption for securing data at rest."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Encryption Procedure"],
    "objectives": ["Data Protection Objective"],
    "standards": ["Encryption Standard"],
    "domains": ["Security Domain"]
}

2. Access Control

sentence = "Configuring multi-factor authentication for all remote access."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Authentication Procedure", "Access Control Procedure"],
    "objectives": ["Access Management Objective"],
    "standards": ["Authentication Standard", "Access Control Standard"],
    "domains": ["Security Domain"]
}

3. Data Backup

sentence = "Performing regular backups and storing them in a secure offsite location."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Backup Procedure", "Data Recovery Procedure"],
    "objectives": ["Data Availability Objective"],
    "standards": ["Backup Standard", "Disaster Recovery Standard"],
    "domains": ["Operational Continuity Domain"]
}

4. Incident Response

sentence = "Establishing an incident response plan to address security breaches."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Incident Response Procedure"],
    "objectives": ["Incident Management Objective"],
    "standards": ["Incident Response Standard"],
    "domains": ["Security Domain"]
}

5. Network Security

sentence = "Implementing a firewall to protect the internal network from unauthorized access."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Firewall Configuration Procedure"],
    "objectives": ["Network Security Objective"],
    "standards": ["Network Security Standard"],
    "domains": ["Security Domain"]
}

6. User Training

sentence = "Conducting regular security awareness training for all employees."
predictions = predict(model, sentence)
print(predictions)

Possible Output:

{
    "procedures": ["Training and Awareness Procedure"],
    "objectives": ["Human Resource Security Objective"],
    "standards": ["Security Training Standard"],
    "domains": ["Human Resources Domain"]
}

These examples demonstrate how the model might map sentences to different procedures, objectives, standards, and domains based on the context of the sentence. The actual output will depend on the training data and the modelâ€™s performance after fine-tuning.












Step 1: Data Preprocessing
We need to convert the labels into a binary format for multi-label classification and tokenize the sentences using the Roberta tokenizer.

Code:
python
Copy code
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MultiLabelBinarizer
from transformers import RobertaTokenizer, RobertaModel, RobertaPreTrainedModel, AdamW
import torch.nn as nn

# Load tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# Assuming `filtered_df` is the DataFrame with the structure you provided.
# The DataFrame has columns: 'sentence', 'procedure', 'objective', 'standard', 'domain'

# Convert the text column to tokens and apply padding/truncation
def tokenize_sentence(sentence):
    return tokenizer(sentence, padding='max_length', truncation=True, max_length=256, return_tensors="pt")['input_ids'].squeeze()

# Tokenizing the sentences
filtered_df['tokenized'] = filtered_df['extended_text'].apply(lambda x: tokenize_sentence(x))

# Use MultiLabelBinarizer to encode multi-label outputs
mlb_procedure = MultiLabelBinarizer()
mlb_objective = MultiLabelBinarizer()
mlb_standard = MultiLabelBinarizer()
mlb_domain = MultiLabelBinarizer()

procedure_labels = mlb_procedure.fit_transform(filtered_df['procedure'])
objective_labels = mlb_objective.fit_transform(filtered_df['objective'])
standard_labels = mlb_standard.fit_transform(filtered_df['standard'])
domain_labels = mlb_domain.fit_transform(filtered_df['domain'])

# Dataset preparation
class HierarchicalDataset(Dataset):
    def __init__(self, sentences, procedures, objectives, standards, domains):
        self.sentences = sentences
        self.procedures = procedures
        self.objectives = objectives
        self.standards = standards
        self.domains = domains

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, idx):
        return {
            'input_ids': self.sentences[idx],
            'procedures': torch.tensor(self.procedures[idx], dtype=torch.float),
            'objectives': torch.tensor(self.objectives[idx], dtype=torch.float),
            'standards': torch.tensor(self.standards[idx], dtype=torch.float),
            'domains': torch.tensor(self.domains[idx], dtype=torch.float),
        }

# Prepare dataset and DataLoader
dataset = HierarchicalDataset(
    sentences=filtered_df['tokenized'].tolist(),
    procedures=procedure_labels,
    objectives=objective_labels,
    standards=standard_labels,
    domains=domain_labels
)

train_loader = DataLoader(dataset, batch_size=16, shuffle=True)
Step 2: Model Definition
We'll define a model based on Roberta for multi-label classification. Each output (procedures, objectives, standards, domains) will be predicted separately.

Code:
python
Copy code
class HierarchicalRoberta(RobertaPreTrainedModel):
    def __init__(self, config, num_procedures, num_objectives, num_standards, num_domains):
        super(HierarchicalRoberta, self).__init__(config)
        self.roberta = RobertaModel(config)

        # Define classifiers for each hierarchical level
        self.procedure_classifier = nn.Linear(config.hidden_size, num_procedures)
        self.objective_classifier = nn.Linear(config.hidden_size, num_objectives)
        self.standard_classifier = nn.Linear(config.hidden_size, num_standards)
        self.domain_classifier = nn.Linear(config.hidden_size, num_domains)

        self.init_weights()

    def forward(self, input_ids, attention_mask=None, labels=None):
        # Get RoBERTa output
        outputs = self.roberta(input_ids, attention_mask=attention_mask)
        sequence_output = outputs[0][:, 0, :]  # Use [CLS] token output

        # Predict each level sequentially
        procedure_logits = self.procedure_classifier(sequence_output)
        objective_logits = self.objective_classifier(sequence_output)
        standard_logits = self.standard_classifier(sequence_output)
        domain_logits = self.domain_classifier(sequence_output)

        return procedure_logits, objective_logits, standard_logits, domain_logits
Step 3: Training Loop
Code:
python
Copy code
# Model initialization
num_procedures = len(mlb_procedure.classes_)
num_objectives = len(mlb_objective.classes_)
num_standards = len(mlb_standard.classes_)
num_domains = len(mlb_domain.classes_)

model = HierarchicalRoberta.from_pretrained('roberta-base', 
                                            num_procedures=num_procedures, 
                                            num_objectives=num_objectives, 
                                            num_standards=num_standards, 
                                            num_domains=num_domains)

# Training setup
optimizer = AdamW(model.parameters(), lr=5e-5)
criterion = nn.BCEWithLogitsLoss()

# Training loop
def train_model(model, train_loader, optimizer, criterion, num_epochs=5):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for batch in train_loader:
            optimizer.zero_grad()

            input_ids = batch['input_ids'].to(torch.int64)
            procedures = batch['procedures']
            objectives = batch['objectives']
            standards = batch['standards']
            domains = batch['domains']

            procedure_logits, objective_logits, standard_logits, domain_logits = model(input_ids)

            loss_procedures = criterion(procedure_logits, procedures)
            loss_objectives = criterion(objective_logits, objectives)
            loss_standards = criterion(standard_logits, standards)
            loss_domains = criterion(domain_logits, domains)

            loss = loss_procedures + loss_objectives + loss_standards + loss_domains
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')

# Train the model
train_model(model, train_loader, optimizer, criterion, num_epochs=3)
Step 4: Inference & Output Format
To predict the labels for a new sentence and return the output in your desired format:

Code:
python
Copy code
def predict(model, sentence):
    model.eval()
    tokens = tokenize_sentence(sentence).unsqueeze(0)  # Add batch dimension
    with torch.no_grad():
        procedure_logits, objective_logits, standard_logits, domain_logits = model(tokens)

    # Apply sigmoid to get probabilities
    procedure_probs = torch.sigmoid(procedure_logits).squeeze().cpu().numpy()
    objective_probs = torch.sigmoid(objective_logits).squeeze().cpu().numpy()
    standard_probs = torch.sigmoid(standard_logits).squeeze().cpu().numpy()
    domain_probs = torch.sigmoid(domain_logits).squeeze().cpu().numpy()

    # Convert probabilities to binary predictions (threshold can be adjusted)
    procedure_preds = procedure_probs > 0.5
    objective_preds = objective_probs > 0.5
    standard_preds = standard_probs > 0.5
    domain_preds = domain_probs > 0.5

    # Map binary predictions to class names
    procedures = mlb_procedure.inverse_transform([procedure_preds])[0]
    objectives = mlb_objective.inverse_transform([objective_preds])[0]
    standards = mlb_standard.inverse_transform([standard_preds])[0]
    domains = mlb_domain.inverse_transform([domain_preds])[0]

    return {
        "procedures": list(procedures),
        "objectives": list(objectives),
        "standards": list(standards),
        "domains": list(domains)
}

# Example usage
sentence = "Implementing AES-256 encryption for securing data at rest."
predictions = predict(model, sentence)
print(predictions)
Step 5: Model Evaluation
To evaluate the model's performance, you can calculate accuracy, precision, recall, and F1-score.

Code:
python
Copy code
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate_model(model, data_loader):
    model.eval()
    all_procedure_preds, all_objective_preds, all_standard_preds, all_domain_preds = [], [], [], []
    all_procedure_labels, all_objective_labels, all_standard_labels, all_domain_labels = [], [], [], []
    
    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch['input_ids'].to(torch.int64)
            procedures = batch['procedures']
            objectives = batch['objectives']
            standards = batch['standards']
            domains = batch['domains']
            
            procedure_logits, objective_logits, standard_logits, domain_logits = model(input_ids)
            
            procedure_preds = (torch.sigmoid(procedure_logits) > 0.5).cpu().numpy()
            objective_preds = (torch.sigmoid(objective_logits) > 0.5).cpu().numpy()
            standard_preds = (torch.sigmoid(standard_logits) > 0.5).cpu().numpy()
            domain_preds = (torch.sigmoid(domain_logits) > 0.5).cpu().numpy()
            
            all_procedure_preds.extend(procedure_preds)
            all_objective_preds.extend(objective_preds)
            all_standard_preds.extend(standard_preds)
            all_domain_preds.extend(domain_preds)
            
            all_procedure_labels.extend(procedures.cpu().numpy())
            all_objective_labels.extend(objectives.cpu().numpy())
            all_standard_labels.extend(standards.cpu().numpy())
            all_domain_labels.extend(domains.cpu().numpy())
    
    print(f"Procedure Accuracy: {accuracy_score(all_procedure_labels, all_procedure_preds)}")
    print(f"Objective Accuracy: {accuracy_score(all_objective_labels, all_objective_preds)}")
    print(f"Standard Accuracy: {accuracy_score(all_standard_labels, all_standard_preds)}")
    print(f"Domain Accuracy: {accuracy_score(all_domain_labels, all_domain_preds)}")

# Example usage
evaluate_model(model, train_loader)
This complete code provides a robust pipeline from preprocessing to model evaluation. You can adjust the number of epochs and learning rate depending on the size and complexity of your data.
